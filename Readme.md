# Llama-3.2-1B-Instruct-korQuAD-v1
<div align="center">

π¤— [**Hugging Face**](https://huggingface.co/NakJun/Llama-3.2-1B-Instruct-korQuAD-v1) - **21.9K Downloads**  

</div>

**Llama-3.2-1B-Instructλ¥Ό κΈ°λ°μΌλ΅ ν•κµ­μ–΄ μ§μμ‘λ‹µ νƒμ¤ν¬λ¥Ό fine-tuning, inference, evaluation ν•λ” ν”„λ΅μ νΈ**

## basic
- κΈ°λ³Έ λ¨λΈ: Llama-3.2-1B-Instruct
- ν•™μµ λ°μ΄ν„°μ…‹: KorQuAD v1.0
- ν•™μµ λ°©λ²•: LoRA (Low-Rank Adaptation)
- μ£Όμ” νƒμ¤ν¬: ν•κµ­μ–΄ μ§μμ‘λ‹µ

## history
### v1.0.0(2024-10-02)
- μ΄κΈ° λ²„μ „ μ—…λ΅λ“
- KorQuAD v1.0 λ°μ΄ν„°μ…‹ νμΈνλ‹

### v1.1.0(2024-10-30)
- λ¨λΈ ν”„λ΅¬ν”„νΈ λ° ν•™μµ λ°©λ²• κ°μ„ 
- KorQuAD evaluate μ½”λ“ μ μ©

## evaluation
| λ¨λΈ | Exact Match | F1 Score |
|------|-------------|----------|
| Llama-3.2-1B-Instruct-v1 | 18.86 | 37.2 |
| Llama-3.2-1B-Instruct-v2 | 36.07 | 59.03 |
β€» https://korquad.github.io/category/1.0_KOR.htmlμ evaluation script μ‚¬μ©

## code description
```
1. fine_tuning.py
- λ¨λΈ νμΈνλ‹ μ½”λ“
- training_params λ³€κ²½ν•μ—¬ ν•™μµ ν•μ΄νΌνλΌλ―Έν„° μμ • κ°€λ¥

2. inference.py
- λ¨λΈ μΈνΌλ°μ¤ μ½”λ“
- λ¨λΈ κ²½λ΅ λ³€κ²½ ν›„ μ‚¬μ© κ°€λ¥

3. evaluation.py
- λ¨λΈ μ΄λ°Έλ¥μ—μ΄μ… μ½”λ“
- KorQuAD evaluateλ¥Ό μ„ν• json μ €μ¥

4. evaluate-v1.0.py
- KorQuAD evaluate μ½”λ“ μ μ©
- ν‰κ°€ μ§€ν‘ μ¶λ ¥(Exact Match, F1 Score)
$python evaluate-v1.0.py [dataset_file] [prediction_file]
```

## learning parameters
- step: 2000
- λ°°μΉ ν¬κΈ°: 1
- ν•™μµλ¥ : 2e-4
- μµν‹°λ§μ΄μ €: AdamW (32-bit)
- LoRA μ„¤μ •:
  - r: 16
  - lora_alpha: 16
  - λ€μƒ λ¨λ“: ["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "down_proj", "up_proj"]
  - lora_dropout: 0.01

## Contact
- njsung1217@gmail.com
- https://github.com/nakjun
- https://huggingface.co/NakJun/Llama-3.2-1B-Instruct-korQuAD-v1
